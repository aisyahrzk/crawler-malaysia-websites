{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2604aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "import urllib.request\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "704ad624",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrefs = []\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c9d6277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl(url):\n",
    "    while True:\n",
    "        try:\n",
    "            r = requests.get(url,headers = headers)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(1.0)\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "    div = soup.find_all('div', attrs = {\"class\":\"read-title\"})\n",
    "    \n",
    "    if len(div) == 0:\n",
    "        return\n",
    "\n",
    "    for link in soup.find_all('div', attrs = {\"class\":\"read-title\"}):\n",
    "\n",
    "        href = link.find('a').get('href')\n",
    "\n",
    "        hrefs.append(href)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9758e0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_worker = 10\n",
    "\n",
    "\n",
    "for t in range(1):\n",
    "    \n",
    "    hrefs = []\n",
    "    url = 'https://www.utusansarawak.com.my'\n",
    "    print(url)\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, \"lxml\")\n",
    "    a = soup.find_all('a')\n",
    "    a = [a_.get('href') for a_ in a if a_.get('href')]\n",
    "    pgno = [a_ for a_ in a if 'paged' in a_]\n",
    "    max_page = max([int(a_.split('?paged=')[1]) for a_ in pgno])\n",
    "    print(max_page)\n",
    "\n",
    "    \n",
    "    for i in tqdm(range(1, max_page + 1, max_worker)):\n",
    "        aranged = np.arange(i, i + max_worker)\n",
    "        urls = [f'{url}?paged={a}' for a in aranged]\n",
    "        with ThreadPoolExecutor(max_workers=max_worker) as executor:\n",
    "            futures = {executor.submit(crawl, url): url for url in urls}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            future.result()\n",
    "    \n",
    "    hrefs = list(set(hrefs))\n",
    "    with open(f'utusansarawak-link.json', 'a') as f:\n",
    "        json.dump(hrefs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "201f0ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrefs = list(set(hrefs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2123796b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13327"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab7665e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('utusansarawak-link.json', 'a') as f:\n",
    "    json.dump(hrefs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40167269",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('utusansarawak-link.json') as fopen:\n",
    "    hrefs = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62357135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_url(x):\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            r = requests.get(x, headers=headers)\n",
    "            \n",
    "            if r.status_code == 508:\n",
    "                time.sleep(20)\n",
    "                continue\n",
    "                \n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(5.0)\n",
    "    \n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "    try:\n",
    "        headline = soup.find('h1', class_=\"entry-title\").text\n",
    "        h = soup.find('div', class_=\"entry-content read-details\")\n",
    "        p = [p.text for p in h.find_all(\"p\")]\n",
    "    except Exception as e:\n",
    "        print('error in link:'+ x)\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    \n",
    "    data = {'url': x, 'headline': headline, 'content': p}\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1354c3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▋                                                                                                                                                                             | 13/619 [00:21<17:03,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in link:https://www.utusansarawak.com.my/?tag=dr-awang-azman\n",
      "'NoneType' object has no attribute 'text'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████████████████████████▌                                                                                                                                    | 153/619 [04:10<20:22,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in link:https://www.utusansarawak.com.my/?tag=dr-suffian-mansor\n",
      "'NoneType' object has no attribute 'text'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████████████████████████████████████████▏                                                                                                                                  | 159/619 [04:20<13:20,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in link:https://www.utusansarawak.com.my/?tag=kadir-dikoh\n",
      "'NoneType' object has no attribute 'text'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████████████████████████████████████▍                                                                                                                      | 202/619 [05:23<14:14,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in link:https://www.utusansarawak.com.my/?tag=adi-badiozaman-tuah\n",
      "'NoneType' object has no attribute 'text'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████████████████████████████████████████████████▉                                                                                                      | 260/619 [07:05<08:22,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in link:https://www.utusansarawak.com.my/?page_id=38700\n",
      "'NoneType' object has no attribute 'find_all'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 619/619 [16:15<00:00,  1.58s/it]\n"
     ]
    }
   ],
   "source": [
    "max_workers = 3\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [executor.submit(process_url, x) for x in not_in_list2]\n",
    "    \n",
    "    for future in tqdm(futures, total=len(not_in_list2)):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            with open('utusansarawak.jsonl', 'a') as f:\n",
    "                json.dump(result, f)\n",
    "                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11268e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "\n",
    "# Open the JSONL file and extract URLs into a list\n",
    "file_path = 'utusansarawak.jsonl'\n",
    "url_list1 = []\n",
    "with jsonlines.open(file_path) as reader:\n",
    "    for obj in reader:\n",
    "        url_list1.append(obj['url'])\n",
    "\n",
    "\n",
    "\n",
    "# Find URLs in list 1 that are not in list 2\n",
    "not_in_list2 = [url for url in hrefs if url not in url_list1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbd8f47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(not_in_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de948a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
